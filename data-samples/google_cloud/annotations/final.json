{
  "V8br4RDzg1RsCw6zWQEv": {
    "title": "Incident affecting Google BigQuery",
    "severity": "none",
    "status": "resolved",
    "start_timezone": "PDT",
    "start_time": "2023-09-28 06:00",
    "end_timezone": "PDT",
    "end_time": "2023-09-28 17:12",
    "summary": "On 28 September 2023, Google BigQuery users experienced issues with slot autoscaling[1], purchasing new capacity commitments[2], and propagation delays in reservation assignment[3] updates in US multi-region for a period of 11 hours, 12 minutes.\n* [1] <https://cloud.google.com/bigquery/docs/slots-autoscaling-intro>\n* [2] <https://cloud.google.com/bigquery/docs/reservations-details>\n* [3] <https://cloud.google.com/bigquery/docs/reservations-assignments>",
    "impact": "On 28 September 2023, from 06:00 to 17:12 US/Pacific, Google BigQuery users in the US multi-region were unable to purchase additional slots through autoscaling or new capacity commitments. Additionally, reservation assignment propagation would have been delayed.",
    "root cause": "When a BigQuery customer purchases slots, either directly through the Reservations API[4] or through the Autoscaler, the request is sent to a Reservation server in that region. The Reservation server performs permission and quota checks and sends a request to the Capacity Manager server to approve capacity. In order to calculate available capacity in the region, Capacity Manager maintains a list that maps users to different data centers within the region. This information is continuously synchronized to a backend database. On 27 September 2023, an issue with the size of the data written to the database resulted in errors for some transactions. By 28 September 2023, at 06:00 US/Pacific, the transactions began to fail consistently, causing the Capacity Management system to enter a crash loop and preventing calculation of available capacity in the region and causing failures in slot purchase approval.\n* [4] <https://cloud.google.com/bigquery/docs/reference/reservations/rpc>",
    "mitigation": "Google engineers were alerted to the issue by internal monitoring on 28 September 2023 at 06:48 US/Pacific and immediately started an investigation. Engineers initially determined that the start of the issue aligned with a recent release and initiated a rollback at 10:13 US/Pacific. At 10:42 US/Pacific, testing showed that the rollback had not mitigated the issue. Due to the nature and scope of the issue, engineers began manually approving slot requests. At 11:50 US/Pacific, engineers implemented auto-approval for all slot requests in the US multi-region as a temporary mitigation while the root cause was investigated further. Engineers were able to fully mitigate the issue at 17:12 US/Pacific by reducing the size of the database transaction. Once the mitigation was confirmed, engineers rolled back the temporary auto-approval change.",
    "long-term mitigation": "* Short term, we are enhancing the retry logic for project assignment mappings when errors are detected in the BigQuery capacity mapping system.\n* Short term, we are working to optimize the reservation database to reduce contention and reduce runtime dependencies on it.\n* In the medium-term, we are working to decouple reservation processing from the capacity mapping system to make capacity allocation independent of reservation mapping.",
    "diagnosis": "N/A",
    "workaround": "N/A",
    "updates": "11:46 PDT on 28 Sep 2023:\nSummary: Google BigQuery users are experiencing issues with slot autoscaling and with purchasing new commitments in multi-region US Description: Our Engineering team has identified a mitigation for the issue and are working to initiate mitigation work. We will provide more information by Thursday, 2023-09-28 12:20 US/Pacific. Diagnosis: BigQuery users in multi-region US may see issues with scaling up slots and purchasing new commitments. Workaround: None at this time.\n\n12:31 PDT on 28 Sep 2023:\nSummary: Google BigQuery users are experiencing issues with slot autoscaling and with purchasing new commitments in multi-region US Description: Upon further investigation, our engineering team concluded that the previously identified mitigation does not resolve the issue. Our engineers are continuing to investigate the issue to identify a mitigation for the issue. We will provide more information by Thursday, 2023-09-28 13:10 US/Pacific. Diagnosis: BigQuery users in multi-region US may see issues with scaling up slots and purchasing new commitments. Workaround: None at this time.\n\n13:11 PDT on 28 Sep 2023:\nSummary: Google BigQuery users are experiencing issues with slot autoscaling and with purchasing new commitments in multi-region US Description: Mitigation work is currently underway by our engineering team. We do not have an ETA for mitigation at this point. We will provide more information by Thursday, 2023-09-28 13:45 US/Pacific. Diagnosis: BigQuery users in multi-region US may see issues with scaling up slots and purchasing new commitments. Workaround: None at this time.\n\n13:49 PDT on 28 Sep 2023:\nSummary: Google BigQuery users are experiencing issues with slot autoscaling and with purchasing new commitments in multi-region US Description: Mitigation work is currently underway by our engineering team. The mitigation is expected to complete by Thursday, 2023-09-28 14:50 US/Pacific. We will provide more information by Thursday, 2023-09-28 15:00 US/Pacific. Diagnosis: BigQuery users in multi-region US may see issues with scaling up slots and purchasing new commitments. Workaround: None at this time.\n\n14:37 PDT on 28 Sep 2023:\nSummary: Google BigQuery users are experiencing issues with slot autoscaling and with purchasing new commitments in multi-region US Description: Mitigation work is currently underway by our engineering team. The mitigation is expected to complete by Thursday, 2023-09-28 16:30 US/Pacific. We will provide more information by Thursday, 2023-09-28 16:40 US/Pacific. Diagnosis: BigQuery users in multi-region US may see issues with scaling up slots and purchasing new commitments. Workaround: None at this time.\n\n16:18 PDT on 28 Sep 2023:\nSummary: Google BigQuery users are experiencing issues with slot autoscaling and with purchasing new commitments in multi-region US Description: Mitigation work is currently underway by our engineering team. A mitigation has been implemented which has fixed capacity purchase and autoscaling requests. Reservation assignment updates are still experiencing propagation delays. We will provide an update by Thursday, 2023-09-28 17:30 US/Pacific with current details. Diagnosis: BigQuery users in multi-region US may see issues with scaling up slots, purchasing new commitments, and reservation assignment updates have propagation delays. Workaround: None at this time.\n\n17:33 PDT on 28 Sep 2023:\nThe issue with Google BigQuery has been resolved for all affected users as of Thursday, 2023-09-28 17:12 US/Pacific. Capacity slot purchases are now succeeding and reservation assignments are propagating correctly.",
    "is_confused": false,
    "is_included": true,
    "is_completed": true,
    "is_saved": true,
    "last_save_time": "2025-05-11 05:35"
  },
  "oSkQCweQ7xWmgu1g1Jps": {
    "title": "Incident affecting VMWare engine, Google Compute Engine",
    "severity": "none",
    "status": "resolved",
    "start_timezone": "PST",
    "start_time": "2024-01-23 07:45",
    "end_timezone": "PST",
    "end_time": "2024-01-23 09:20",
    "summary": "Google Cloud VMware Engine (GCVE) customers were unable to navigate to the GCVE Portal in Cloud Console, or perform management actions for VMware resources using the GCVE API or gcloud CLI, for a duration of 1 hour 35 minutes.",
    "impact": "Affected Services and Features: Google Cloud VMware Engine\n\nRegions/Zones: Global\n\nCustomer Impact: GCVE customers were unable to access the GCVE Portal through Cloud Console and would have experienced errors when using the GCVE API and gcloud CLI to perform management actions on VMware resources. VMware workloads were not impacted and remained accessible through vCenter.",
    "root cause": "From preliminary analysis, the root cause of the issue was expired certificates.",
    "mitigation": "The issue was mitigated on 23 January, 2024 09:20 US/Pacific by installing new certificates.",
    "long-term mitigation": "N/A",
    "diagnosis": "N/A",
    "workaround": "N/A",
    "updates": "09:08 PST on 23 Jan 2024:\nSummary: Multi-Region: Google Cloud VMWare Engine Portal Unavailable in Google Cloud Console Description: We are experiencing an issue with Google Cloud VMWare Engine Portal. Our engineering team continues to investigate the issue. We will provide an update by Tuesday, 2024-01-23 09:40 US/Pacific with current details. Diagnosis: Customers are unable to navigate to the Google Cloud VMWare Engine Portal in the Google Cloud Console. The UI, API, and CLI are not available and there is no impact to VM workloads. Workaround: None at this time.\n\n09:21 PST on 23 Jan 2024:\nThe issue with Google Cloud VMWare Engine Portal in the Google Cloud Console has been resolved for all affected users as of Tuesday, 2024-01-23 09:20 US/Pacific.",
    "is_confused": false,
    "is_included": true,
    "is_completed": true,
    "is_saved": true,
    "last_save_time": "2025-03-24 15:55"
  },
  "uSjFxRvKBheLA4Zr5qHs": {
    "title": "Incident affecting Google Cloud Networking, Cloud Load Balancing",
    "severity": "none",
    "status": "resolved",
    "start_timezone": "PDT",
    "start_time": "2023-04-26 01:58",
    "end_timezone": "PDT",
    "end_time": "2023-04-26 04:56",
    "summary": "Google Cloud Load Balancing customers experienced issues applying configuration updates to their external HTTPS load balancers globally for a duration of 2 hours and 58 minutes.",
    "impact": "Affected Services and Features: Google Cloud Load Balancing - Control Plane\n\nRegions/Zones: Global\n\nCustomer Impact:\n* Affected customers were unable to make changes to their External HTTPS Load Balancer configuration. Both user interface and gcloud command line interface (CLI) were affected.",
    "root cause": "From preliminary analysis, the root cause of the issue was due to a recent rollout.",
    "mitigation": "The issue was fully mitigated on Wednesday, 26 April 2023 04:56 US/Pacific once the rollback and configuration propagation completed.",
    "long-term mitigation": "N/A",
    "diagnosis": "N/A",
    "workaround": "N/A",
    "updates": "03:36 PDT on 26 Apr 2023:\nSummary: Cloud Load Balancing: unable to mage changes into configuration External HTTPS Load Balancer globally Description: We are experiencing an issue with Cloud Load Balancing. Our engineering team continues to investigate the issue. We will provide an update by Wednesday, 2023-04-26 04:30 US/Pacific with current details. Diagnosis: Customers will not be able to make changes to their External HTTPS Load Balancer configuration globally. Both user interface and gcloud command line are affected. Workaround: None at this time.\n\n03:42 PDT on 26 Apr 2023:\nSummary: Cloud Load Balancing: unable to mage changes into configuration External HTTPS Load Balancer globally Description: Mitigation work is currently underway by our engineering team. We do not have an ETA for mitigation at this point. We will provide more information by Wednesday, 2023-04-26 05:00 US/Pacific. Diagnosis: Customers will not be able to make changes to their External HTTPS Load Balancer configuration globally. Both user interface and gcloud command line are affected. Workaround: None at this time.\n\n04:40 PDT on 26 Apr 2023:\nSummary: Cloud Load Balancing: unable to mage changes into configuration External HTTPS Load Balancer globally Description: A mitigation has been applied and we're currently working through the backlog of the impacted projects and the customers should see improvements. We will communicate once the issue has fully been resolved. We do not have an ETA for mitigation at this point. We will provide more information by Wednesday, 2023-04-26 06:30 US/Pacific. Diagnosis: Customers will not be able to make changes to their External HTTPS Load Balancer configuration globally. Both user interface and gcloud command line are affected. Workaround: None at this time.\n\n05:00 PDT on 26 Apr 2023:\nThe issue with Cloud Load Balancing has been resolved for all affected projects as of Wednesday, 2023-04-26 05:00 US/Pacific.",
    "is_confused": false,
    "is_included": true,
    "is_completed": true,
    "is_saved": true,
    "last_save_time": "2025-03-24 07:52"
  }
}